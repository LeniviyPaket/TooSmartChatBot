{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generator based on Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to create the model that chooses the next word\n",
    "\n",
    "This time it'll be Markov Chain\n",
    "\n",
    "It makes predictions based on current state and probabilities of next state to come real\n",
    "More info can be found here: https://en.wikipedia.org/wiki/Markov_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MarkovChain(object):\n",
    "    def __init__(self, transition_prob, splitters = [\" \"], s_prob = [1]):\n",
    "        self.transition_prob = transition_prob\n",
    "        self.states = list(transition_prob.keys())\n",
    "        self.splitters = splitters #[\"\", \".\", \",\", \";\", \":\", \" --\"]\n",
    "        self.s_prob = s_prob #[0.8, 0.05, 0.05, 0.025, 0.025, 0.05]\n",
    " \n",
    "    def next_state(self, current_state):\n",
    "        arr = []\n",
    "        norm = 1 #sum(list(self.transition_prob[current_state].values()))\n",
    "        for next_state in self.states:\n",
    "            if next_state not in self.transition_prob[current_state]:\n",
    "                arr.append(0)\n",
    "            else:\n",
    "                arr.append(self.transition_prob[current_state][next_state] / norm)\n",
    "        return np.random.choice(self.states, p = arr)\n",
    " \n",
    "    def generate_states(self, current_state, no=10):\n",
    "        future_states = []\n",
    "        for i in range(no):\n",
    "            next_state = self.next_state(current_state)\n",
    "            future_states.append(next_state + np.random.choice(self.splitters, p = self.s_prob))\n",
    "            current_state = next_state\n",
    "        return future_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell creates a formatted list from given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open(\"ViM.txt\").read() + open(\"Frai_Maks__Chuchak.txt\").read() + open(\"sorokin.txt\").read()\n",
    "text = \"\"\n",
    "\n",
    "for c in txt:\n",
    "    if c.isalpha():\n",
    "        text += c\n",
    "    #elif c in [\", \", \". \", \"... \", \"; \", \": \", \" -- \", \" - \", \" \"]:\n",
    "    #    text += \" \" + c\n",
    "    else:\n",
    "        text += \" \"\n",
    "\n",
    "text = (text.lower()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [\", \", \". \", \"... \", \"; \", \": \", \" -- \", \" - \", \" \"]\n",
    "sp = dict(zip(_, [txt.count(__) for __ in _]))\n",
    "sp[\". \"] -= 3 * sp[\"... \"]\n",
    "sp[\" \"] -= sp[\", \"] + sp[\". \"] + sp[\"... \"] + sp[\"; \"] + sp[\": \"] + 2 * sp[\" -- \"] + 2 * sp[\" - \"]\n",
    "\n",
    "norm = sum(list(sp.values()))\n",
    "\n",
    "for __ in sp:\n",
    "    sp[__] /= norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this one counts the transition probabilities between each pair of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some debug may be needed\n",
    "#UPD: works fine enough\n",
    "\n",
    "trans_prob = {}\n",
    "\n",
    "for i in range(len(text) - 1):\n",
    "    wd1 = text[i]\n",
    "    wd2 = text[i + 1]\n",
    "    if wd1 not in trans_prob:\n",
    "        trans_prob[wd1] = {}\n",
    "    if wd2 not in trans_prob[wd1]:\n",
    "        trans_prob[wd1][wd2] = 0\n",
    "    trans_prob[wd1][wd2] += 1\n",
    "\n",
    "for wd in trans_prob:\n",
    "    norm = sum(list(trans_prob[wd].values()))\n",
    "    for q in trans_prob[wd]:\n",
    "        trans_prob[wd][q] /= norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it's time to initialize our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_chain = MarkovChain(transition_prob = trans_prob, splitters = list(sp.keys()), s_prob = list(sp.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cells are examples and tests of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "безупречное. и опять, стал девушкой, на: левом фланге: высшее только мешаю хожу тут я непременно, попытался изобразить: в фижмах это уже после слов тяжести: небрежно, разминая ноги все спасибо за, отсылкой бенигсена напрягая все. само собою радовало ее от барабана несколько дней маловато но буксгевден стоял болконский, в: оглядываясь кругом высвободив ногу с дворни но и знала но перевод это объяснить себе. \n"
     ]
    }
   ],
   "source": [
    "print(*word_chain.generate_states(current_state = np.random.choice(text), no = np.random.randint(20, 80)), sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = text[3785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['николая',\n",
       " 'и',\n",
       " 'ясно',\n",
       " 'как',\n",
       " 'бы',\n",
       " 'совершенно',\n",
       " 'откровенна',\n",
       " 'сказала',\n",
       " 'она',\n",
       " 'в',\n",
       " 'лесу',\n",
       " 'граф',\n",
       " 'вдруг',\n",
       " 'при',\n",
       " 'удовлетворении',\n",
       " 'своих',\n",
       " 'то',\n",
       " 'услужливо',\n",
       " 'вынул',\n",
       " 'из']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_chain.generate_states(current_state = word1, no = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ты',\n",
       " 'постой',\n",
       " 'пожалуста',\n",
       " 'голубчик',\n",
       " 'я',\n",
       " 'без',\n",
       " 'перевода',\n",
       " 'нет',\n",
       " 'андрей',\n",
       " 'я',\n",
       " 'здесь',\n",
       " 'присядем',\n",
       " 'артиллеристы',\n",
       " 'сдули',\n",
       " 'нагоревшие',\n",
       " 'пальники',\n",
       " 'офицер',\n",
       " 'в',\n",
       " 'редком',\n",
       " 'взгляде',\n",
       " 'как',\n",
       " 'и',\n",
       " 'та',\n",
       " 'же',\n",
       " 'стоявшие',\n",
       " 'перед',\n",
       " 'домом',\n",
       " 'в',\n",
       " 'нерешительности',\n",
       " 'итти',\n",
       " 'сударыня',\n",
       " 'в',\n",
       " 'долг',\n",
       " 'я',\n",
       " 'ложусь',\n",
       " 'спать',\n",
       " 'николай',\n",
       " 'в',\n",
       " 'русскую',\n",
       " 'батарею']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_chain.generate_states(current_state = np.random.choice(text), no = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some trash code\n",
    "\n",
    "It can be unoptimized version of some parts or some kind of attempt to first create a very fine-working thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsevolod/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file /home/vsevolod/Desktop/Inf_project/ViM.txt\n",
      "Words processed: 500K     Vocab size: 414K  \n",
      "Vocab size (unigrams + bigrams): 238567\n",
      "Words in train file: 584772\n",
      "Words written: 500K\r"
     ]
    }
   ],
   "source": [
    "word2vec.word2phrase(\"/home/vsevolod/Desktop/Inf_project/ViM.txt\", \"/home/vsevolod/Desktop/Inf_project/ViM-phrases.txt\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file /home/vsevolod/Desktop/Inf_project/ViM-phrases.txt\n",
      "Vocab size: 13257\n",
      "Words in train file: 462253\n",
      "Alpha: 0.000371  Progress: 99.31%  Words/thread/sec: 269.67k  "
     ]
    }
   ],
   "source": [
    "word2vec.word2vec(\"/home/vsevolod/Desktop/Inf_project/ViM-phrases.txt\", \"/home/vsevolod/Desktop/Inf_project/ViM.bin\", size = 100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file /home/vsevolod/Desktop/Inf_project/ViM.txt\n",
      "Vocab size: 12470\n",
      "Words in train file: 490352\n",
      "Alpha: 0.000102  Progress: 100.00%  Words/thread/sec: 277.98k  "
     ]
    }
   ],
   "source": [
    "word2vec.word2clusters(\"/home/vsevolod/Desktop/Inf_project/ViM.txt\", \"/home/vsevolod/Desktop/Inf_project/ViM-clusters.txt\", 100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.load(\"/home/vsevolod/Desktop/Inf_project/ViM.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works fine\n",
    "\n",
    "trans_prob = {}\n",
    "wd2ind = {}\n",
    "\n",
    "i = 0\n",
    "for i in range(len(text)):\n",
    "    if text[i] not in wd2ind:\n",
    "        wd2ind[text[i]] = []\n",
    "        trans_prob[text[i]] = {}\n",
    "    wd2ind[text[i]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works fine, do not touch\n",
    "\n",
    "for wd in trans_prob:\n",
    "    arr = []\n",
    "    for i in wd2ind[wd]:\n",
    "        if (i < len(text) - 1):\n",
    "            arr.append(text[i + 1])\n",
    "    for w in set(arr):\n",
    "        trans_prob[wd][w] = arr.count(w) / len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does not work properly\n",
    "\n",
    "keys = list(trans_prob.keys())\n",
    "\n",
    "def getword(text, wd2ind, trans_prob, start, step):\n",
    "    for i in range(start, len(trans_prob), step):\n",
    "        wd = keys[i]\n",
    "        arr = []\n",
    "        for i in wd2ind[wd]:\n",
    "            if (i < len(text) - 1):\n",
    "                arr.append(text[i + 1])\n",
    "        for w in set(arr):\n",
    "            trans_prob[wd][w] = arr.count(w) / len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#even this...\n",
    "\n",
    "k = int(len(text) ** 1/2) + 1\n",
    "if __name__ == \"__main__\":\n",
    "    man = mp.Manager()\n",
    "    text_ = man.list(text)\n",
    "    wd2ind_ = man.dict(wd2ind)\n",
    "    trans_prob_ = man.dict(trans_prob)\n",
    "    for j in range(k):\n",
    "        p = mp.Process(target = getword, args = (text_, wd2ind_, trans_prob_, j, k))\n",
    "        p.start()\n",
    "        #p.join()\n",
    "trans_prob = trans_prob_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
