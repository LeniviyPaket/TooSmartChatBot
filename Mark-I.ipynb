{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsevolod/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file /home/vsevolod/Desktop/Inf_project/ViM.txt\n",
      "Words processed: 500K     Vocab size: 414K  \n",
      "Vocab size (unigrams + bigrams): 238567\n",
      "Words in train file: 584772\n",
      "Words written: 500K\r"
     ]
    }
   ],
   "source": [
    "word2vec.word2phrase(\"/home/vsevolod/Desktop/Inf_project/ViM.txt\", \"/home/vsevolod/Desktop/Inf_project/ViM-phrases.txt\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file /home/vsevolod/Desktop/Inf_project/ViM-phrases.txt\n",
      "Vocab size: 13257\n",
      "Words in train file: 462253\n",
      "Alpha: 0.000371  Progress: 99.31%  Words/thread/sec: 269.67k  "
     ]
    }
   ],
   "source": [
    "word2vec.word2vec(\"/home/vsevolod/Desktop/Inf_project/ViM-phrases.txt\", \"/home/vsevolod/Desktop/Inf_project/ViM.bin\", size = 100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file /home/vsevolod/Desktop/Inf_project/ViM.txt\n",
      "Vocab size: 12470\n",
      "Words in train file: 490352\n",
      "Alpha: 0.000102  Progress: 100.00%  Words/thread/sec: 277.98k  "
     ]
    }
   ],
   "source": [
    "word2vec.word2clusters(\"/home/vsevolod/Desktop/Inf_project/ViM.txt\", \"/home/vsevolod/Desktop/Inf_project/ViM-clusters.txt\", 100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.load(\"/home/vsevolod/Desktop/Inf_project/ViM.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the code really starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class MarkovChain(object):\n",
    "    def __init__(self, transition_prob):\n",
    "        self.transition_prob = transition_prob\n",
    "        self.states = list(transition_prob.keys())\n",
    "        self.splitters = [\"\", \".\", \",\", \";\", \":\", \" ---\"]\n",
    "        self.s_prob = [0.8, 0.05, 0.05, 0.025, 0.025, 0.05]\n",
    " \n",
    "    def next_state(self, current_state):\n",
    "        arr = []\n",
    "        norm = 1 #sum(list(self.transition_prob[current_state].values()))\n",
    "        for next_state in self.states:\n",
    "            if next_state not in self.transition_prob[current_state]:\n",
    "                arr.append(0)\n",
    "            else:\n",
    "                arr.append(self.transition_prob[current_state][next_state] / norm)\n",
    "        return np.random.choice(self.states, p = arr)\n",
    " \n",
    "    def generate_states(self, current_state, no=10):\n",
    "        future_states = []\n",
    "        for i in range(no):\n",
    "            next_state = self.next_state(current_state)\n",
    "            future_states.append(next_state + np.random.choice(self.splitters, p = self.s_prob))\n",
    "            current_state = next_state\n",
    "        return future_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open(\"ViM.txt\").read() + open(\"Frai_Maks__Chuchak.txt\").read()\n",
    "text = \"\"\n",
    "\n",
    "for c in txt:\n",
    "    if c.isalpha():\n",
    "        text += c\n",
    "    else:\n",
    "        text += \" \"\n",
    "\n",
    "text = (text.lower()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some debug may be needed\n",
    "#UPD: works fine enough\n",
    "\n",
    "trans_prob = {}\n",
    "\n",
    "for i in range(len(text) - 1):\n",
    "    wd1 = text[i]\n",
    "    wd2 = text[i + 1]\n",
    "    if wd1 not in trans_prob:\n",
    "        trans_prob[wd1] = {}\n",
    "    if wd2 not in trans_prob[wd1]:\n",
    "        trans_prob[wd1][wd2] = 0\n",
    "    trans_prob[wd1][wd2] += 1\n",
    "\n",
    "for wd in trans_prob:\n",
    "    norm = sum(list(trans_prob[wd].values()))\n",
    "    for q in trans_prob[wd]:\n",
    "        trans_prob[wd][q] /= norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_chain = MarkovChain(transition_prob = trans_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сердцу --- очень; впечатлительный твой отец очень милая катишь велела; мне не ложка а убив своего друга. быстрые шумные невысокие волны --- очень нужно создавать: волшебные миры. создаю. то время я почитатель montesquieu, сказал сперанский выходя из воронежской губернии пока дом, прокаженных; отчего произошло трудно определить. какая сила воли осталась с тобой будут приняты немедленно спасать ребенка старый генерал; мак теряет силу заявляя только --- одну дюжину принесу пообещал джуффин рассеянно и не, для багратиона ничего, не было, чем. ехать в том. чтобы\n"
     ]
    }
   ],
   "source": [
    "print(*word_chain.generate_states(current_state = np.random.choice(text), no = 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = text[3785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['николая',\n",
       " 'и',\n",
       " 'ясно',\n",
       " 'как',\n",
       " 'бы',\n",
       " 'совершенно',\n",
       " 'откровенна',\n",
       " 'сказала',\n",
       " 'она',\n",
       " 'в',\n",
       " 'лесу',\n",
       " 'граф',\n",
       " 'вдруг',\n",
       " 'при',\n",
       " 'удовлетворении',\n",
       " 'своих',\n",
       " 'то',\n",
       " 'услужливо',\n",
       " 'вынул',\n",
       " 'из']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_chain.generate_states(current_state = word1, no = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ты',\n",
       " 'постой',\n",
       " 'пожалуста',\n",
       " 'голубчик',\n",
       " 'я',\n",
       " 'без',\n",
       " 'перевода',\n",
       " 'нет',\n",
       " 'андрей',\n",
       " 'я',\n",
       " 'здесь',\n",
       " 'присядем',\n",
       " 'артиллеристы',\n",
       " 'сдули',\n",
       " 'нагоревшие',\n",
       " 'пальники',\n",
       " 'офицер',\n",
       " 'в',\n",
       " 'редком',\n",
       " 'взгляде',\n",
       " 'как',\n",
       " 'и',\n",
       " 'та',\n",
       " 'же',\n",
       " 'стоявшие',\n",
       " 'перед',\n",
       " 'домом',\n",
       " 'в',\n",
       " 'нерешительности',\n",
       " 'итти',\n",
       " 'сударыня',\n",
       " 'в',\n",
       " 'долг',\n",
       " 'я',\n",
       " 'ложусь',\n",
       " 'спать',\n",
       " 'николай',\n",
       " 'в',\n",
       " 'русскую',\n",
       " 'батарею']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_chain.generate_states(current_state = np.random.choice(text), no = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works fine\n",
    "\n",
    "trans_prob = {}\n",
    "wd2ind = {}\n",
    "\n",
    "i = 0\n",
    "for i in range(len(text)):\n",
    "    if text[i] not in wd2ind:\n",
    "        wd2ind[text[i]] = []\n",
    "        trans_prob[text[i]] = {}\n",
    "    wd2ind[text[i]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works fine, do not touch\n",
    "\n",
    "for wd in trans_prob:\n",
    "    arr = []\n",
    "    for i in wd2ind[wd]:\n",
    "        if (i < len(text) - 1):\n",
    "            arr.append(text[i + 1])\n",
    "    for w in set(arr):\n",
    "        trans_prob[wd][w] = arr.count(w) / len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does not work properly\n",
    "\n",
    "keys = list(trans_prob.keys())\n",
    "\n",
    "def getword(text, wd2ind, trans_prob, start, step):\n",
    "    for i in range(start, len(trans_prob), step):\n",
    "        wd = keys[i]\n",
    "        arr = []\n",
    "        for i in wd2ind[wd]:\n",
    "            if (i < len(text) - 1):\n",
    "                arr.append(text[i + 1])\n",
    "        for w in set(arr):\n",
    "            trans_prob[wd][w] = arr.count(w) / len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#even this...\n",
    "\n",
    "k = int(len(text) ** 1/2) + 1\n",
    "if __name__ == \"__main__\":\n",
    "    man = mp.Manager()\n",
    "    text_ = man.list(text)\n",
    "    wd2ind_ = man.dict(wd2ind)\n",
    "    trans_prob_ = man.dict(trans_prob)\n",
    "    for j in range(k):\n",
    "        p = mp.Process(target = getword, args = (text_, wd2ind_, trans_prob_, j, k))\n",
    "        p.start()\n",
    "        #p.join()\n",
    "trans_prob = trans_prob_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
